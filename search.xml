<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>k8s环境下的日志收集方案</title>
      <link href="/K8S/K8S/k8s%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E6%96%B9%E6%A1%88/"/>
      <url>/K8S/K8S/k8s%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E6%96%B9%E6%A1%88/</url>
      <content type="html"><![CDATA[<h3 id="日志需求">日志需求</h3><ol><li>业务方只管将日志写到磁盘，至于磁盘上文件，如何同步到<code>ElasticSearch</code>中，用户不需要花过多的精力关注</li><li>在采集端做解析</li><li>使用json进行传输数据</li></ol><p>日志需要避免直接写入<code>kafka</code>中，当出现问题后，如果kafka同步到<code>ElasticSearch</code>也出现了问题，将导致无法快速解决问题。在采集端做解析，有两个考虑，首先在采集端做解析，就能统一后端的日志传输格式（json）；其次避免了集中式的日志采集，能够减少出现异常时异常影响范围，而且也能减少<code>Logstash</code>端的压力。</p><h3 id="常见的日志收集框架">常见的日志收集框架</h3><ul><li>fluent-bit</li><li>fluentd</li><li>filebeat</li></ul><p>filebeat不提供解析的功能，如果需要解析的话，需要在elasticsearch开启ingest特性。而fluentd和fluent-bit相较而言比较类似，fluent-bit只是比fluentd更轻量级，都提供解析功能，并且统一输出为json格式。但是在使用fluent-bit一段时间后，发现fluent-bit并不是很稳定。</p><h3 id="常见k8s日志收集策略">常见k8s日志收集策略</h3><p>大体上有两种日志收集方案: Sidecar方案和Node方案。</p><ul><li><p>Sidecar方案<br>给每一个需要收集日志的Pod中添加一个附属的日志收集容器，业务容器与日志收集容器共享磁盘。</p><p>其优点如下:</p><ol><li>可以为每个业务定制日志收集策略</li></ol><p>其缺点如下:</p><ol><li>浪费资源</li><li>如果日志容器宕机，会影响业务容器</li></ol></li><li><p>Node方案<br>在每个节点上部署一个日志收集实例，采集当前节点下的所有Pod的日志信息</p><p>其优点如下:</p><ol><li>占用资源小</li><li>日志收集实例不会影响到业务容器的状态</li></ol><p>其缺点如下:</p><ol><li>不能定制化日志收集策略</li></ol></li></ul><h4 id="log-pilot的原理">log-pilot的原理</h4><p>log-pilot会以DaemonSet的形式运行在k8s集群，由于daemonSet的特性，会使每一个节点上有且仅有一个log-pilot在运行。在每一个节点上，log-pilot会以Pod的形式存在。该Pod有如下关键资源:</p><ul><li>该Pod会将节点的<code>/</code>目录挂载进Pod里面的<code>/host</code>目录，这样log-pilot在Pod里面能够访问节点的所有文件</li><li>该Pod里面，会存在fluentd或者filebeat进程，能够进行日志采集</li></ul><p>而log-pilot会做如下事情：</p><ul><li>首先会监听当前节点的docker事件，当出现<code>start</code>或者<code>restart</code>事件时，会从事件中获取容器ID</li><li>通过 <code>docker inspect</code> 获取容器信息。主要获取容器的磁盘挂载信息和环境变量。</li><li>通过结合环境变量传入的信息，和磁盘的挂载信息，能够在当前Pod的<code>/host</code>找到相应的日志</li><li>log-pilot根据以上信息，生成filebeat或者fluentd的配置文件</li><li>通过发送信号，重启filebeat或者fluentd，从而采集新的容器日志</li></ul><h3 id="最终的日志方案">最终的日志方案</h3><p>访方案仅仅针对<strong>k8s环境</strong>，需要在k8s集群中部署一个log-pilot的daemonset，利用daemonset的特性，会保证每一个k8s所有节点上会自动部署仅仅一个log-pilot，而log-pilot则负责当前节点的所有日志收集工作。log-pilot采用了fluentd的实现。整个流程如下:</p><p> <img src="pics/日志方案流程图.png" alt="日志方案流程图.png"></p><p>为了能够保证log-pilot能够正常工作，在整个过程中有如下规范。规范主要分为三大类：</p><ul><li><p>日志路径规范</p><ul><li>在每一个k8s节点上，都会存在一个<code>/logs1</code>的目录，该目录是通过<code>LVM</code>的方式进行管理，能够实现磁盘的动态扩容。而每一个线上需要收集日志的Daemonset、Deployment需要将节点上的<code>/logs1</code>，通过<code>hostPath</code>的方式挂载到<code>Pod</code>上，<code>Pod</code>里面的进程需要将日志收集到挂载的目录上。</li><li><p>因为当前k8s上的所有<code>Pod</code>都会将日志写到<code>/logs1</code>目录下，为了避免日志相互影响，所以日志的目录有如下的规范。<br><code>/data/logs/{team}/{project}/{tier}-{pod名字}.log</code></p><ul><li><code>team</code>，团队名，英文名</li><li><code>project</code>，项目名，英文名</li><li><code>tier</code>，模块名，英文名</li><li><code>Pod名字</code></li></ul></li></ul></li><li><p><strong>日志清理规范</strong><br>磁盘的清理，需要每个业务线根据申请的磁盘大小，设定磁盘清理策略。</p></li><li><p>ElasticSearch的索引前缀规范<br>和DBA沟通过，DBA做了如下的规范:</p><ul><li>日志必须是json格式</li><li>主题名应该业务名加功能名，比如qbus-message-log</li><li><code>ElasticSearch</code>中的每一条记录的<code>@timestamp</code>字段，默认为日志进入<code>ElasticSearch</code>的时间，如果需要将日志中的时间作为es中的<code>@timestamp</code>字段，那么日志中的时间字段必须为<code>timestamp</code>，其格式为时间戳。</li><li>Ckafka的主题名和<code>ElasticSearch</code>的索引名前缀保持一致，默认按天新建索引。现在不支持自定义。</li></ul></li></ul><p>访方案的优缺点:</p><p>优点:</p><ul><li>业务团队无需要花费过多的精力去做日志收集，这是一种声明的方式，如果你需要日志收集功能就通过环境变量传入参数</li><li>不必创建额外的日志收集进程，整个节点只会存在一个收集程序</li></ul><p>缺点:</p><ul><li>不灵活，无法针对某些日志进行特定操作，比如修改数据类型</li><li>一旦日志采集程序出异常，将会影响当前节点的所有Pod的日志采集</li><li>Log-Pilot如果需要大的调整，影响面会很大，且不容易升级</li><li>线上Log-pilot出现问题，担心以现在的运维能力可能不能及时解决问题</li></ul><h3 id="如何部署?">如何部署?</h3><ul><li>在每一个节点上，以<code>LVM</code>的方式管理一个<code>/logs1</code>目录</li><li><p>在k8s集群中创建log-pilot服务</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: log-pilot</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: log-pilot</span><br><span class="line">  namespace: devops</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: log-pilot</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: log-pilot</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: kuainiujinke-registry</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line">      containers:</span><br><span class="line">        - name: log-pilot</span><br><span class="line">          image: registry.kuainiujinke.com/middleware/log-pilot:fluentd-1.2.6</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 200m</span><br><span class="line">              memory: 200Mi</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 500m</span><br><span class="line">              memory: 500Mi</span><br><span class="line">          env:</span><br><span class="line">            - name: &quot;NODE_NAME&quot;</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: spec.nodeName</span><br><span class="line">            - name: &quot;LOGGING_OUTPUT&quot;</span><br><span class="line">              value: &apos;kafka&apos;</span><br><span class="line">            - name: &quot;KAFKA_BROKERS&quot;</span><br><span class="line">              value: &apos;10.1.1.21:9092&apos;</span><br><span class="line">            - name: &quot;FLUENTD_BUFFER_CHUNK_LIMIT_SIZE&quot;</span><br><span class="line">              value: &apos;1MB&apos;</span><br><span class="line">            - name: &quot;FLUENTD_BUFFER_TOTAL_LIMIT_SIZE&quot;</span><br><span class="line">              value: &apos;300MB&apos;</span><br><span class="line">            - name: &quot;FLUENTD_BUFFER_CHUNK_FULL_THRESHOLD&quot;</span><br><span class="line">              value: &apos;0.95&apos;</span><br><span class="line">            - name: &quot;FLUENTD_FLUSH_MODE&quot;</span><br><span class="line">              value: &apos;interval&apos;</span><br><span class="line">            - name: &quot;FLUENTD_FLUSH_INTERVAL&quot;</span><br><span class="line">              value: &apos;3&apos;</span><br><span class="line">            - name: &quot;FLUENTD_FLUSH_THREAD_COUNT&quot;</span><br><span class="line">              value: &apos;1&apos;</span><br><span class="line">            - name: &quot;FLUENTD_FLUSH_AT_SHUTDOWN&quot;</span><br><span class="line">              value: &apos;true&apos;</span><br><span class="line">            - name: &quot;KAFKA_OUTPUT_DATA_TYPE&quot;</span><br><span class="line">              value: &apos;json&apos;</span><br><span class="line">            - name: &quot;KAFKA_MAX_SEND_RETRIES&quot;</span><br><span class="line">              value: &apos;3&apos;</span><br><span class="line">            - name: &quot;KAFKA_REQUIRED_ACKS&quot;</span><br><span class="line">              value: &apos;1&apos;</span><br><span class="line">            - name: &quot;KAFKA_ACK_TIMEOUT&quot;</span><br><span class="line">              value: &apos;1&apos;</span><br><span class="line">            - name: &quot;KAFKA_DISCARD_KAFKA_DELIVERY_FAILED&quot;</span><br><span class="line">              value: &apos;false&apos;</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">                - /pilot/healthz</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 2</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: sock</span><br><span class="line">              mountPath: /var/run/docker.sock</span><br><span class="line">            - name: root</span><br><span class="line">              mountPath: /host</span><br><span class="line">              readOnly: true</span><br><span class="line">            - name: localtime</span><br><span class="line">              mountPath: /etc/localtime</span><br><span class="line">              readOnly: true</span><br><span class="line">            - name: pilot-pos</span><br><span class="line">              mountPath: /pilot/pos</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              add:</span><br><span class="line">                - SYS_ADMIN</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">        - name: sock</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/run/docker.sock</span><br><span class="line">        - name: root</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /</span><br><span class="line">        - name: localtime</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /etc/localtime</span><br><span class="line">        - name: pilot-pos</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /tmp/pos</span><br><span class="line">            type: DirectoryOrCreate</span><br></pre></td></tr></table></figure><p>其中由于线上环境启用了容忍与污点机制，所以当某一个组需要日志采集功能的话，需要在以上daemonset的配置上再添加上容忍的配置</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tolerations:</span><br><span class="line">  - key: 污点的key</span><br><span class="line"> operator: &quot;Exists&quot;</span><br><span class="line"> effect: &quot;NoSchedule&quot;</span><br></pre></td></tr></table></figure></li></ul><h3 id="如何接入？">如何接入？</h3><ul><li><p>将<code>/logs1</code>以<code>host</code>方式挂载到Pod里面的<code>/data/logs</code>目录下，然后将日志按<code>/data/logs/{team}/{project}/{tier}/{pod名字}/*.log</code>规范写入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- name: logs</span><br><span class="line">  hostPath:</span><br><span class="line">    path: /logs1</span><br><span class="line">    type: Directory</span><br></pre></td></tr></table></figure></li><li><p>通过Deployment或者StatefulSet的helm模板环境变量传入日志路径及解析相关信息</p><ol><li><code>aliyun_logs_$name</code><ol><li><code>$name</code> 可以自定义，<code>$name</code> 不能含有下划线’_’，用于声明日志</li><li>value 可以是 “stdout” ，或者为容器内日志文件的绝对路径</li></ol></li><li><code>aliyun_logs_$name.format</code> 日志格式，目前支持以下格式<ol><li>none：无格式纯文本。</li><li>json：json 格式，每行一个完整的 json 字符串。推荐使用。</li><li>regexp：正则，需要再添加一个环境变量，key为<code>aliyun_logs_$name.format.pattern</code>，value为就是正则表达式，可以在<code>https://rubular.com/</code>上进行验证</li></ol></li><li><code>aliyun_logs_$name.tags</code>，收集日志时，额外增加的字段，格式为 k1=v1,k2=v2，每个 key-value 之间使用逗号分隔，例如 <code>aliyun_logs_access.tags=&quot;name=hello,stage=test&quot;</code>，每一个日志，至少需要在添加如下几个标签:<ol><li>team，团队名</li><li>project，项目名</li><li>tier，模块名</li><li>app，应用名</li><li>env，环境，例如prod，test，stage，dev</li></ol></li><li><code>aliyun_logs_$name.target</code>，用于指定日志写入的<code>ckafka</code>主题名，实例名不需要配置。</li></ol></li></ul><p>按如上方式进行部署后，就能直接在kibana上通过如下操作进行查看:</p><ul><li>添加<code>index pattern</code></li><li>在<code>Discover</code>中进行查看</li></ul><h3 id="注意事项">注意事项</h3><ul><li>Dockerfile中创建目录，会被挂载的目录所覆盖，例如:<br>在Dockerfile中创建<code>/data/logs/AB/CD</code>目录，然后将宿主机的<code>/logs1</code>挂载Pod的到<code>/data/logs</code>目录下，如果<code>/logs1</code>目录下并没有<code>AB</code>目录，那么进入到容器里面会发现在Dockerfile中创建的目录<code>/data/logs/AB/CD</code>并不存在。</li></ul>]]></content>
      
      <categories>
          
          <category> K8S </category>
          
      </categories>
      
      
        <tags>
            
            <tag> K8S </tag>
            
            <tag> 日志 </tag>
            
            <tag> Log-pilot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Centos命令PAC科学上网</title>
      <link href="/Linux/Linux/Centos%E5%91%BD%E4%BB%A4PAC%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
      <url>/Linux/Linux/Centos%E5%91%BD%E4%BB%A4PAC%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</url>
      <content type="html"><![CDATA[<p>科学上网的整个过程如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请求 ==&gt; privoxy ==&gt; ss ==&gt; ss server</span><br></pre></td></tr></table></figure><p>请求通常是http和https，通过配置环境变量，将请求转发到privoxy，而privoxy利用PAC技术，选择将流量转到ss客户端或者直接请求，当请求走ss客户端时，请求会被转发到国外的ss服务器上，从国外的ss服务器上访问指定的url获取数据，再将数据还回。</p><h3 id="安装">安装</h3><p>依赖于:</p><ul><li>python</li><li>pip</li><li>privoxy</li><li>shadowsocks</li></ul><p>安装命令如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install epel-release &amp;&amp; yum -y install python-pip &amp;&amp; pip install shadowsocks &amp;&amp; yum -y install privoxy</span><br></pre></td></tr></table></figure><h3 id="配置">配置</h3><ul><li><p>ss配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">/etc/shadowsocks.json文件，没有则创建</span><br><span class="line">&#123;</span><br><span class="line">  &quot;server&quot;:&quot;1.2.3.4&quot;,</span><br><span class="line">  &quot;server_port&quot;:18081,</span><br><span class="line">  &quot;local_address&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">  &quot;local_port&quot;:1080,</span><br><span class="line">  &quot;password&quot;:&quot;xxxx&quot;,</span><br><span class="line">  &quot;method&quot;:&quot;aes-256-gcm&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## 配置说明：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;server&quot;: &quot;1.2.3.4&quot;,          # 服务器IP</span><br><span class="line">  &quot;server_port&quot;: 18081,         # 服务器Port</span><br><span class="line">  &quot;local_address&quot;: &quot;0.0.0.0&quot;,   # 本地监听IP</span><br><span class="line">  &quot;local_port&quot;: 1080,           # 本地监听Port</span><br><span class="line">  &quot;method&quot;: &quot;aes-256-gcm&quot;,      # 加密方式</span><br><span class="line">  &quot;password&quot;: &quot;xxxx&quot;            # server密码</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>命令为： <code>sslocal -c /etc/shadowsocks.json -d start</code></p></li><li><p>privoxy配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -4sSkLO https://raw.github.com/zfl9/gfwlist2privoxy/master/gfwlist2privoxy</span><br><span class="line">bash gfwlist2privoxy &apos;127.0.0.1:1080&apos;</span><br><span class="line">mv -f gfwlist.action /etc/privoxy</span><br><span class="line">echo &apos;actionsfile gfwlist.action&apos; &gt;&gt; /etc/privoxy/config</span><br></pre></td></tr></table></figure><p>命令如下: <code>systemctl start/restart/stop privoxy.service</code></p></li><li><p>代理配置（环境变量）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># privoxy 默认监听端口为 8118</span><br><span class="line">proxy=&quot;http://127.0.0.1:8118&quot;</span><br><span class="line">export http_proxy=$proxy</span><br><span class="line">export https_proxy=$proxy</span><br><span class="line">export no_proxy=&quot;localhost, 127.0.0.1, ::1&quot;</span><br><span class="line"></span><br><span class="line"># no_proxy 环境变量是指不经过 privoxy 代理的地址或域名</span><br><span class="line"># 只能填写具体的 IP、域名后缀，多个条目之间使用 &apos;,&apos; 逗号隔开</span><br><span class="line"># 比如: export no_proxy=&quot;localhost, 192.168.1.1, ip.cn, chinaz.com&quot;</span><br><span class="line"># 访问 localhost、192.168.1.1、ip.cn、*.ip.cn、chinaz.com、*.chinaz.com 将不使用代理</span><br></pre></td></tr></table></figure></li></ul><h3 id="调试">调试</h3><ul><li><p>以调试模式启动privoxy</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop privoxy.service</span><br><span class="line">privoxy &lt;(cat /etc/privoxy/config; echo -e &apos;debug 1\ndebug 2\ndebug 1024\ndebug 4096\ndebug 8192&apos;)</span><br></pre></td></tr></table></figure></li><li><p>通过日志判断PAC模式是否生效</p><ul><li>查看日志: <code>tail -f /var/log/privoxy/logfile</code></li><li>执行命令:<ul><li><code>curl -4sSkL https://www.baidu.com</code></li><li><code>curl -4sSkL https://www.google.com</code></li></ul></li></ul><p>首先需要确保能够<code>curl</code>到数据，然后分别对比在访问百度和Google时的Debug日志，其中在访问Google时，会提示 <code>Overriding forwarding settings based on &#39;forward-socks5 127.0.0.1:1080 .&#39;</code>，这表明PAC生效。</p></li></ul>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Centos </tag>
            
            <tag> 科学上网 </tag>
            
            <tag> GFW </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java应用高并发优化漫谈</title>
      <link href="/Java/Java/Java%E5%BA%94%E7%94%A8%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%E6%BC%AB%E8%B0%88/"/>
      <url>/Java/Java/Java%E5%BA%94%E7%94%A8%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%E6%BC%AB%E8%B0%88/</url>
      <content type="html"><![CDATA[<h3 id="一、背景">一、背景</h3><p>现在<code>QBus</code>每天有<strong>1.1～1.2</strong>亿次访问量，其中消息发送和删除的请求有<strong>9~10</strong>千万次，由两台4核8G的机器提供服务，消息拉取接口有<strong>1～2千万</strong>左右的访问量，同样也是由两台4核8G的机器提供服务。以下就是我们在提高服务整体性能上所做出的优化。</p><h3 id="二、优化思路">二、优化思路</h3><p>在谈优化思路前，首先需要搞清楚一个<code>QBus</code>请求是如何从各个服务器走到<code>qbus-server</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sdk ==&gt; 域名解析 ==&gt; http协议 ==&gt; kong(nginx) ==&gt; qbus-server</span><br></pre></td></tr></table></figure><p>以下是针对每个环节提供的一些优化点，大家可以深入了解一下:</p><ul><li><p>SDK<br><br>TCP的keepalive，复用连接，使用连接池</p></li><li><p>域名解析如何优化呢？<br><br>CDN，选择就近资源</p></li><li><p>HTTP协议优化如何优化呢？<br><br>现在比较流行的是<code>HTTP/1.1</code>，但是可以的话，用<code>HTTP/2</code>，性能将提高很多</p></li><li><p>kong优化？<br><br>操作系统优化和nginx的优化</p></li><li><p><code>qbus-server</code>如何优化？<br><br>操作系统优化、jvm优化、tomcat优化、代码优化</p></li></ul><p>主要叙述的是<code>qbus-server</code>的优化，以下将会从这几个方面讲解一下<code>qbus-server</code>中的优化:</p><ul><li>操作系统优化</li><li>JVM优化</li><li>Tomcat优化</li><li>代码优化</li></ul><h3 id="三、内核及网络优化">三、内核及网络优化</h3><p>以下主要基于腾讯云上的Centos7的内核、网络优化。大家可以根据各自的情况进行相应的调整。</p><p>调整步骤:</p><ul><li>用<code>root</code>权限编辑<code>/etc/sysctl.conf</code>文件</li><li>执行<code>sysctl -p</code>使配置生效</li></ul><p>特别注意在修改线上文件前，请先备份。注释的为默认值配置</p><h4 id="3-1_关闭无用的资源">3.1 关闭无用的资源</h4><ul><li><p>关闭<code>ipv6</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line"></span><br><span class="line"># net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line"></span><br><span class="line"># net.ipv6.conf.lo.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 1</span><br></pre></td></tr></table></figure></li><li><p>数据转发<br><br>可以实现数据转发，通常用于将一张网卡的数据转发到另一张网发上</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv4.ip_forward = 0</span><br><span class="line">net.ipv4.ip_forward = 0</span><br></pre></td></tr></table></figure></li><li><p>不处理无源地址的网络包</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv4.conf.all.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.all.accept_source_route = 0</span><br><span class="line"></span><br><span class="line"># net.ipv4.conf.default.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-2_安全方面优化">3.2 安全方面优化</h4><ul><li><p><code>开启防欺骗攻击</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv4.conf.default.rp_filter = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 1</span><br></pre></td></tr></table></figure></li><li><p><code>避免ping flood攻击</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv4.icmp_echo_ignore_broadcasts = 1</span><br><span class="line">net.ipv4.icmp_echo_ignore_broadcasts = 1</span><br></pre></td></tr></table></figure></li><li><p>开启防SYN洪水攻击，当出现SYN等待队列溢出时，启用cookies来处理</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-3_TCP优化">3.3 TCP优化</h4><ul><li><p><code>keepalive</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效，默认是7200s</span><br><span class="line"># net.ipv4.tcp_keepalive_time = 7200</span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line"></span><br><span class="line"># keepalive探针，当对方不给予回应时，发送的探针的次数</span><br><span class="line"># net.ipv4.tcp_keepalive_probes = 9</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line"></span><br><span class="line"># keepalive探针的间隔，单位秒</span><br><span class="line"># net.ipv4.tcp_keepalive_intvl = 75</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 15</span><br></pre></td></tr></table></figure></li></ul><pre><code><span class="escape">`H</span>TTP<span class="escape">`和</span><span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`分</span>别有什么作用？<span class="escape">`H</span>TTP/<span class="number">1.0</span><span class="escape">`协</span>议，每一个HTTP请求开始，都将打开一个TCP连接，请求结束，都将会关闭TCP连接。从<span class="escape">`H</span>TTP/<span class="number">1.1</span><span class="escape">`开</span>始，提供了<span class="escape">`k</span>eepalive<span class="escape">`功</span>能，指的是同时请求同一个服务的同一台机器时，请求结束后，并不会立即关闭TCP连接，而是保留一段时间，在保留时间段内的请求，会复用TCP连接，过期后，才会真正结束TCP连接。TCP的<span class="escape">`k</span>eepalive<span class="escape">`指</span>的是<span class="escape">`T</span>CP<span class="escape">`协</span>议层面上的一个检测机制，当某一个TCP连接没有数据传输后，会存在着一个定时器用于确定一个<span class="escape">`T</span>CP<span class="escape">`连</span>接是否依然存活，以决定是否关闭当前连接。<span class="label">从上面的解释大家也能看出他们的区别，它们是两个不同层面上的协议，但是它们会共同影响`TCP`连接的生命周期。从时间上，`TCP`的`keepalive`和`HTTP`的`keepalive`会了出现如下几种情况:</span><span class="number">1</span>. <span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`和</span><span class="escape">`H</span>TTP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`时</span>间一样<span class="number">2</span>. <span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`比</span><span class="escape">`H</span>TTP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`时</span>间大<span class="number">3</span>. <span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`比</span><span class="escape">`H</span>TTP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`时</span>间小因为<span class="escape">`H</span>TTP<span class="escape">`是</span>比<span class="escape">`T</span>CP<span class="escape">`更</span>高层的协议，当<span class="escape">`H</span>TTP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`和</span><span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`的</span>时间一样，或者比<span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`小</span>，其逻辑会是正常的，因为HTTP先关，再关TCP嘛。但是如果<span class="escape">`H</span>TTP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`比</span><span class="escape">`T</span>CP<span class="escape">`的</span><span class="escape">`k</span>eepalive<span class="escape">`大</span>，则有可能会出现，<span class="escape">`H</span>TTP<span class="escape">`的</span>连接依然在复用，但是<span class="escape">`T</span>CP<span class="escape">`已</span>经关闭。</code></pre><ul><li><p><code>TIME_WAIT</code>状态的重用及回收</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 启TCP时间戳，用来计算往返时间RTT（Round-Trip Time）和防止序列号回绕，用于支持tcp_tw_reuse和tcp_tw_recycle</span><br><span class="line"># net.ipv4.tcp_timestamps = 1</span><br><span class="line">net.ipv4.tcp_timestamps = 1</span><br><span class="line"></span><br><span class="line"># TCP中的TIME_WAIT的状态的重用</span><br><span class="line"># net.ipv4.tcp_tw_reuse = 0</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line"></span><br><span class="line"># TCP中的TIME_WAIT的快速回收，在对外网提供服务时，需要关闭</span><br><span class="line"># net.ipv4.tcp_tw_recycle = 0</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br></pre></td></tr></table></figure></li></ul><pre><code><span class="escape">`T</span>IME-WAIT<span class="escape">`会</span>保持两个周期(<span class="escape">`M</span>S<span class="escape">`)</span>，而一个<span class="escape">`M</span>S<span class="escape">`是</span>一个IP报文最大的存活时间，而两个周期在于客户端发出<span class="escape">`A</span>CK<span class="escape">`到</span>达服务器的过程和数据报来到客户端的过程。只有在两个<span class="escape">`M</span>S<span class="escape">`内</span>没有任何数据，才能让客户端确定再没有任何的数据来自服务器，才能关闭<span class="escape">`S</span>ocket<span class="escape">`。</span><span class="escape">`T</span>IME_WAIT<span class="escape">`的</span>快速回收，是一种基于时间序列的快速回收机制，并不会让<span class="escape">`T</span>IME_WAIT<span class="escape">`状</span>态持续两个周期，而是保持一个重传时间，能够快速释放资源。<span class="escape">`T</span>IME_WAIT<span class="escape">`的</span>重用，当满足特定条件的<span class="escape">`S</span>ocket<span class="escape">`，</span>可以用于接受新的连接，而不用先关闭再连接。</code></pre><ul><li><p><code>TCP</code>内存</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 内核分配给TCP连接的内存，单位是page：</span><br><span class="line">#  第一个数字表示TCP使用的page少于此值时，内核不进行任何处理（干预），</span><br><span class="line">#  第二个数字表示TCP使用的page超过此值时，内核进入“memory pressure”压力模式，</span><br><span class="line">#  第三个数字表示TCP使用的page超过些值时，报“Out of socket memory”错误，TCP 连接将被拒绝</span><br><span class="line"># net.ipv4.tcp_mem = 7658911021191 1531782</span><br><span class="line">net.ipv4.tcp_mem = 88557 118079 177114</span><br><span class="line"></span><br><span class="line"># 为每个TCP连接分配的读缓冲区内存大小，单位是byte</span><br><span class="line">#  第一个数字表示，为TCP连接分配的最小内存，</span><br><span class="line">#  第二个数字表示，为TCP连接分配的缺省内存，</span><br><span class="line">#  第三个数字表示，为TCP连接分配的最大内存</span><br><span class="line"># net.ipv4.tcp_rmem = 4096873806291456</span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 6291456</span><br><span class="line"></span><br><span class="line"># 为每个TCP连接分配的写缓冲区内存大小，单位是byte</span><br><span class="line">#  第一个数字表示，为TCP连接分配的最小内存，</span><br><span class="line">#  第二个数字表示，为TCP连接分配的缺省内存，</span><br><span class="line">#  第三个数字表示，为TCP连接分配的最大内存</span><br><span class="line"># net.ipv4.tcp_wmem = 4096163844194304</span><br><span class="line">net.ipv4.tcp_wmem = 4096 16384 4194304</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>重试次数</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># TCP连接时，SYN 重发的最大次数</span><br><span class="line"># net.ipv4.tcp_syn_retries = 6</span><br><span class="line">net.ipv4.tcp_syn_retries = 1</span><br><span class="line"></span><br><span class="line"># TCP连接时重发ACK的最大次数</span><br><span class="line"># net.ipv4.tcp_synack_retries = 5</span><br><span class="line">net.ipv4.tcp_synack_retries = 1</span><br><span class="line"></span><br><span class="line"># 孤儿sockets废弃前重试的次数</span><br><span class="line"># net.ipv4.tcp_orphan_retries = 0</span><br><span class="line">net.ipv4.tcp_orphan_retries = 0</span><br></pre></td></tr></table></figure></li></ul><pre><code><span class="escape">`孤</span>儿sockets<span class="escape">`指</span>的是已经从进程上下文中删除了，可是还有一些清理工作没有完成的<span class="escape">`s</span>ocket<span class="escape">`。</span></code></pre><ul><li><p>端口范围</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 设置端口范围，提高服务能力</span><br><span class="line"># net.ipv4.ip_local_port_range = 32768 60999</span><br><span class="line">net.ipv4.ip_local_port_range = 1024 65000</span><br></pre></td></tr></table></figure></li><li><p>Other</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 设置FIN_WAIT2的等待时间，单位秒，默认为60</span><br><span class="line"># net.ipv4.tcp_fin_timeout = 60</span><br><span class="line">net.ipv4.tcp_fin_timeout = 2</span><br><span class="line"></span><br><span class="line"># 设置TIME_WAIT的最大个数，大于这个阀值后会被删除</span><br><span class="line"># net.ipv4.tcp_max_tw_buckets = 131072</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 6000</span><br><span class="line"></span><br><span class="line"># 表示SYN队列的长度，默认为1024，可以容纳更多等待连接</span><br><span class="line"># net.ipv4.tcp_max_syn_backlog = 1024</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 100000</span><br><span class="line"></span><br><span class="line"># 用来限制监听(LISTEN)队列最大数据包的数量，超过这个数量就会导致链接超时或者触发重传机制</span><br><span class="line"># net.core.somaxconn = 128</span><br><span class="line">net.core.somaxconn = 100000</span><br><span class="line"></span><br><span class="line"># 即不属于任何进程的tcp socket最大数量. 超过这个数量的socket会被reset, 并同时告警</span><br><span class="line"># net.ipv4.tcp_max_orphans = 131072</span><br><span class="line">net.ipv4.tcp_max_orphans = 100000</span><br><span class="line"></span><br><span class="line"># 当网卡接受数据包的速率, 比kernel处理来的快时, cache这些数据包的队列长度，默认是1000</span><br><span class="line"># net.core.netdev_max_backlog = 1000</span><br><span class="line">net.core.netdev_max_backlog = 32768</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-4_其它">3.4 其它</h4><ul><li><p>日志</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 用于调试内核</span><br><span class="line"># kernel.sysrq = 1</span><br><span class="line">kernel.sysrq = 1</span><br><span class="line"></span><br><span class="line"># 用于在core dump文件中，增加进程ID</span><br><span class="line"># kernel.core_uses_pid = 1</span><br><span class="line">kernel.core_uses_pid = 1</span><br></pre></td></tr></table></figure></li><li><p>内核队列</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 控制一个消息的大小，bytes</span><br><span class="line"># kernel.msgmnb = 65536</span><br><span class="line">kernel.msgmnb = 65536</span><br><span class="line"></span><br><span class="line"># 限制一个队列的最大消息个数</span><br><span class="line"># kernel.msgmax = 65536</span><br><span class="line">kernel.msgmax = 65536</span><br></pre></td></tr></table></figure></li></ul><h3 id="四、JVM优化">四、JVM优化</h3><p>JVM优化主要针对两个方面，<strong>内存</strong>和<strong>GC</strong>，以确保服务的质量和服务所占内存处于一个稳定状态。首先先介绍一下JVM的内存分布和现有<code>GC</code>算法</p><h4 id="4-1_JVM内存">4.1 JVM内存</h4><p>JVM中的内存主要有如下几个部分组成:</p><ul><li><p>程序计数器<br><br>用于指明当前线程需要执行的字节码行；<strong>线程私有</strong>；如果是Java方法，则记录虚拟机字节码指令地址，如果为<code>native</code>方法，则为<code>Undefined</code></p></li><li><p>虚拟机栈<br><br>每一个方法执行时，都将创建一个栈帧，用于记录局部变量、操作栈、动态链接、方法出口等，当方法被调用时，栈帧入栈，执行完成后，出栈。<strong>线程私有</strong>。</p></li><li><p>本地方法栈<br><br>与虚拟机栈类似，唯一的区别就是：虚拟机栈保存Java方法栈帧，而本地方法栈保存native方法栈帧。<strong>线程私有</strong>。</p></li><li><p>堆区<br><br>GC的主要区域，由<strong>所有线程共享</strong>，在虚拟机启动时创建，用于存储对象实例。</p></li><li><p>方法区<br><br>各个线程共享的区域，用于存储已经被虚拟机加载的类信息、final常量、静态变量、编译器即时编译的代码等。</p></li><li><p>直接内存<br><br>不受JVM管理的内存。</p></li></ul><p>而我们所做的优化主要针对堆区，而堆又分成：<code>Eden</code>、<code>Survivor1(From Space)</code>、<code>Survivor2(To Space)</code>、<code>Old</code>，其中<code>Eden</code>、<code>Survivor1(From Space)</code>、<code>Survivor2(To Space)</code>被统称为年轻代，<code>Old</code>是老年代。</p><h4 id="4-2_GC算法">4.2 <code>GC</code>算法</h4><p><code>GC</code>主要用于回收堆内存，而堆主要包含两个部分:</p><ul><li>年轻代</li><li>老年代</li></ul><p>针对年轻代的<code>GC</code>称为<code>Minor GC</code>，针对老年代的<code>GC</code>称为<code>Full GC</code>。</p><p>由于年轻代具有生命周期短的特点，通常采用 <strong>停止-复制</strong>的算法，其主要的算法有:</p><ul><li><p>Serial<br><br>新生代收集器，使用停止复制算法，使用一个线程进行GC，其它工作线程暂停。</p></li><li><p>ParNew<br><br>新生代收集器，使用停止复制算法，Serial收集器的多线程版，用多个线程进行GC，其它工作线程暂停，关注缩短垃圾收集时间。</p></li><li><p>Parallel Scavenge<br><br>新生代收集器，使用停止复制算法，关注CPU吞吐量，即运行用户代码的时间/总时间，比如：JVM运行100分钟，其中运行用户代码99分钟，垃圾收集1分钟，则吞吐量是99%，</p></li></ul><p>针对老年代对象具有数量多，对象大的特点，通常采用 <strong>标记-整理</strong>的算法，其算法有:</p><ul><li><p>Serial Old<br><br>老年代收集器，单线程收集器，使用标记整理的策略，单线程GC，暂停其它工作线程，清除废弃的对象，将幸存的对象放在一起，避免内存碎片。</p></li><li><p>Parallel Old<br><br>老年代，多线程收集器，暂停其它工作线程，清除废弃的对象，将幸存的对象放在一起，避免内存碎片。</p></li><li><p>CMS<br><br>Concurrent Mark Sweep，老年代收集器，致力于获取最短回收停顿时间，使用标记清除算法，多线程，优点是并发收集（用户线程可以和GC线程同时工作），停顿小。</p><ol><li>初始标记， 仅仅标记一下GC Roots能直接关联到的对象</li><li>并发标记， 进行GC Roots Tracing的过程</li><li>重新标记， 修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录</li><li><p>并发清除， 标记某一个对象不可用</p><p>初始标记与重新标记仍然需要停止其它工作线程。其主要的2个过程，都采用并发的操作，能够保证与工作线程一起运行。但是该算法对CPU资源很敏感，CPU越多，越快；无法处理浮动垃圾，即在一次GC过程中，可能又会出现一些垃圾，需要下次GC去处理，因为它没有停止工作线程；会产生大量内存碎片，没有整理。</p></li></ol></li><li><p>G1<br><br>基于“标记-整理”算法实现的收集器，不会产生空间碎片。G1将整个Java堆划分为多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先列表，每次根据允许的收集时间，优先回收垃圾最多的区域。</p></li></ul><h4 id="4-3_JVM优化">4.3 JVM优化</h4><p>为了避免<code>GC</code>带来的停顿影响服务质量，在内存和GC优化过程中会有如下经验:</p><ul><li>年轻代使用<code>ParNew</code>算法，老年代使用<code>CMS</code>算法，能够减少系统由于GC带来的停顿，当然也可以直接用<code>G1</code>算法，<code>QBus</code>线上使用的就是<code>ParNew</code>和<code>CMS</code>的组合</li><li>最大堆和最小堆设置成一样，能够避免扩容引起的<code>Full GC</code></li><li>最大堆的大小，不能超过整个物理机内存的50%</li><li>年轻代的大小，最好占整个堆的 <code>3/8</code></li><li><code>Eden</code>和<code>Survivor</code>的比例是<code>8</code></li><li><code>-XX:+DisableExplicitGC</code>，这个参数慎用，<code>DirectBuffer</code>的内存释放依赖<code>System.gc()</code>，会导致内存泄露。</li></ul><p>除了内存与<code>GC</code>优化外，以下几个方面也是需要优化的:</p><ul><li>打印<code>GC</code>日志</li><li>出现内存问题时，导出内存到文件</li></ul><p>如下是线上的一台<code>QBus</code>机器的配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_OPTS=&quot;-server </span><br><span class="line">                  -XX:+PrintGCDetails </span><br><span class="line">                  -XX:+PrintGCDateStamps </span><br><span class="line">                  -Xloggc:/data/logs/qbus-server/jvm-gc/gc.log </span><br><span class="line">                  -XX:ErrorFile=/data/logs/qbus-server/jvm-error/error.log </span><br><span class="line">                  -Xms4096M </span><br><span class="line">                  -Xmx4096M </span><br><span class="line">                  -Xss228k </span><br><span class="line">                  -Xmn1536M </span><br><span class="line">                  -XX:SurvivorRatio=8 </span><br><span class="line">                  -XX:+UseParNewGC </span><br><span class="line">                  -XX:+UseConcMarkSweepGC </span><br><span class="line">                  -XX:+AggressiveOpts </span><br><span class="line">                  -XX:MaxTenuringThreshold=15 </span><br><span class="line">                  -XX:+CMSParallelRemarkEnabled  </span><br><span class="line">                  -Djava.awt.headless=true&quot;</span><br></pre></td></tr></table></figure><h3 id="五、Tomcat优化">五、Tomcat优化</h3><p>Tomcat的优化主要从如下几个方面进行优化:</p><ul><li>网络模型</li><li>连接池</li><li>线程池</li><li>超时时间</li><li>TCP参数</li></ul><p>下面将从这几个方面谈优化。</p><h4 id="5-1_网络模型">5.1 网络模型</h4><p>Tomcat8.5版本中，<code>Connector</code>的<code>protocol</code>支持三个模式:</p><ul><li><p><code>org.apache.coyote.http11.Http11NioProtocol</code><br><br>同步非阻塞，用Java的NIO实现</p></li><li><p><code>org.apache.coyote.http11.Http11Nio2Protocol</code><br><br>异步非阻塞，用Java的AIO实现</p></li><li><p><code>org.apache.coyote.http11.Http11AprProtocol</code><br><br>异步非阻塞，通过<code>JNI</code>的方式调用核心链接库来处理文档读取和网络传输。该协议会用到如下几个库:</p><ol><li>Apache Portable Run-time libraries(Apache可移植运行库，APR)</li><li>JNI wrappers for APR used by Tomcat (libtcnative)</li><li><p>OpenSSL</p><p><code>APR</code>库，是一个跨平台库，提供与平台无关的API，能够保证同一个API，在不同平台下运行，其结果总是一致的。而<code>libtcnative</code>则会调用<code>APR</code>库进行文档和网络传输的处理。而<code>Tomcat</code>则会通过<code>JNI</code>调用<code>libtcnative</code>库。</p></li></ol></li></ul><p><code>org.apache.coyote.http11.Http11AprProtocol</code>是<code>Tomcat</code>上运行高并发的首选，接下来将介绍如何安装APR库。</p><hr><p>首先创建<code>tomcat-native-install.sh</code>脚本，并添加执行权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">base=`pwd`</span><br><span class="line">#tomcat的安装目录</span><br><span class="line">tomcat_base=$1</span><br><span class="line">#希望编译好的lib放到什么地方</span><br><span class="line">lib_base=$2</span><br><span class="line">    </span><br><span class="line">function install_openssl() &#123;</span><br><span class="line">    openssl=openssl-1.1.0f</span><br><span class="line">    wget https://www.openssl.org/source/$&#123;openssl&#125;.tar.gz</span><br><span class="line">    tar -xf $&#123;openssl&#125;.tar.gz</span><br><span class="line">    cd $&#123;openssl&#125; </span><br><span class="line">    ./config --prefix=$&#123;base&#125;/ssl no-shared -fPIC</span><br><span class="line">    make &amp;&amp; make install_sw</span><br><span class="line">    cd ..</span><br><span class="line">    rm -rf $&#123;openssl&#125; $&#123;openssl&#125;.tar.gz</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">function install_apr() &#123;</span><br><span class="line">    apr=apr-1.6.3</span><br><span class="line">    wget http://archive.apache.org/dist/apr/$&#123;apr&#125;.tar.gz</span><br><span class="line">    tar -xf $&#123;apr&#125;.tar.gz</span><br><span class="line">    cd $&#123;apr&#125;</span><br><span class="line">    ./configure --prefix=$&#123;base&#125;/apr</span><br><span class="line">    make &amp;&amp; make install</span><br><span class="line">    cd ..</span><br><span class="line">    rm -rf $&#123;apr&#125; $&#123;apr&#125;.tar.gz</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">function install_tomcat_native() &#123;</span><br><span class="line">    base_dir=`pwd`</span><br><span class="line">    cd $&#123;tomcat_base&#125;/bin</span><br><span class="line">    pwd</span><br><span class="line">    tar -xf tomcat-native.tar.gz</span><br><span class="line">    cd `ls $&#123;tomcat_base&#125;/bin | grep src`/native</span><br><span class="line">    ./configure --with-apr=$&#123;base&#125;/apr --with-ssl=$&#123;base&#125;/ssl --with-java-home=$JAVA_HOME --prefix=$lib_base</span><br><span class="line">    make &amp;&amp; make install</span><br><span class="line">    cd $base_dir</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">install_openssl</span><br><span class="line">install_apr</span><br><span class="line">install_tomcat_native</span><br><span class="line">    </span><br><span class="line">rm -rf $&#123;base&#125;/apr</span><br><span class="line">rm -rf $&#123;base&#125;/ssl</span><br><span class="line">    </span><br><span class="line">lib=$&#123;lib_base&#125;/lib</span><br><span class="line">echo &apos;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:&apos;$&#123;lib&#125; &gt;&gt; ~/.profile</span><br><span class="line">source ~/.profile</span><br><span class="line">    </span><br><span class="line">echo 编译 Tomcat目录/conf/server.xml，将其中的 Connector 的 protocol 改成 org.apache.coyote.http11.Http11AprProtocol 和</span><br><span class="line">echo org.apache.coyote.ajp.AjpAprProtocol</span><br></pre></td></tr></table></figure><p>然后再用<code>root</code>执行<code>./tomcat-native-install.sh Tomcat的安装目录 APR库的安装位置</code>进行安装，在传参时，需要注意如下两点:</p><ol><li>传入给shell的参数需要全路径</li><li>传给shell的路径参数，最后不需要加上<code>/</code></li></ol><p>例如： <code>./tomcat-native-install.sh /usr/local/services/tomcat /usr/local/services/tomcat-apr/tomcat-native</code></p><p>安装完成后，还需要修改如下配置：</p><ol><li>修改<code>Tomcat目录/conf/server.xml</code>将其中的<code>Connector</code>的<code>protocol</code>改成<code>org.apache.coyote.http11.Http11AprProtocol</code> 和<code>org.apache.coyote.ajp.AjpAprProtocol</code></li><li>修改<code>Tomcat目录/bin/catalina.sh</code>中添加<code>JAVA_OPTS=&quot;$JAVA_OPTS -Djava.library.path=上面APR的安装目录/lib&quot;</code></li></ol><p>重启服务，即可生效。在<code>logs/catalina.out</code>，能看到如下输出，则能确定<code>APR</code>库生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">07-Mar-2019 11:46:15.871 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-apr-8080&quot;]</span><br><span class="line">07-Mar-2019 11:46:15.875 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-apr-8009&quot;]</span><br></pre></td></tr></table></figure><h4 id="5-2_连接池优化">5.2 连接池优化</h4><ul><li><p><code>acceptorThreadCount</code><br><br>在<code>Tomcat</code>中会由专门的<code>accept</code>线程用于接收请求，并将请求转交给工作线程。通常<code>accept</code>线程个数与CPU核数一致，默认值为1</p></li><li><p><code>acceptCount</code><br><br>当已经没有任何可用的工作线程为新的请求提供服务时，会将请求进行缓存。<code>acceptCount</code>则用于指定缓存队列的大小。当请求无法再放入缓存队列后，请求将会被拒绝。通常用户可能会在nginx层面上看到如下的异常:</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">failed (111: Connection refused) while connecting to upstream</span><br></pre></td></tr></table></figure></li><li><p><code>maxConnections</code><br><br>用于设置<code>Tomcat</code>的最大连接数，这仅仅是Tomcat层面上的限制，超过最大连接数后，操作系统层面，仍然会接收请求，只是请求请求将会进入到缓存队列，当缓存队列满后，请求会被阻塞。可以设置为-1，关闭此限制。</p></li></ul><h4 id="5-3_线程池优化">5.3 线程池优化</h4><p>线程池的优化主要有两个方面:</p><ul><li>线程命名</li><li>线程个数</li></ul><p>线程命名是为在排查问题时，通过<code>jstack</code>命令查询，能够区分出哪些是<code>Tomcat</code>线程。而线程个数能够保证服务的稳定运行。<code>QBus</code>服务线上的配置如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot;</span><br><span class="line">              namePrefix=&quot;tomcatThreadPool-&quot;</span><br><span class="line">              maxThreads=&quot;500&quot;</span><br><span class="line">              maxIdleTime=&quot;10000&quot;</span><br><span class="line">              minSpareThreads=&quot;300&quot;/&gt;</span><br></pre></td></tr></table></figure><ul><li><code>name</code> 用于指明线程名字前缀</li><li><code>minSpareThreads</code> 初始化线程个数</li><li><code>maxThreads</code> 线程池的最大线程个数</li><li><code>maxIdleTime</code> 当某一个线程多久未使用，将会被回收，单位毫秒</li></ul><p>通常可以将线程个数的最大个数设置为500，或者更多，然后上线后，通过<code>jstack tomcat线程ID | grep Tomcat线程前缀名 | grep run | wc -l</code>查看线上稳定运行的线程个数，然后再去调整<code>minSpareThreads</code>。</p><p>请注意在Tomcat中的<code>TPS</code>是由<code>maxConnections</code>、<code>acceptCount</code>与<code>maxThreads</code>共同决定的。</p><h4 id="5-4_超时优化">5.4 超时优化</h4><p>Tomcat总体上有如下几个超时设置:</p><ul><li><p><code>connectionTimeout</code><br><br>当客户端与服务器已经建立连接后，等待客户端传输请求头时，最多等待<code>connectionTimeout</code>毫秒</p></li><li><p><code>keepAliveTimeout</code><br><br>针对<code>HTTP/1.1</code>协议，用于设置服务器最大保持连接的时间</p></li><li><p><code>disableUploadTimeout</code>和<code>connectionUploadTimeout</code><br><br>  当<code>disableUploadTimeout</code>为<code>false</code>时，<code>connectionUploadTimeout</code>才会生效。<code>connectionUploadTimeout</code>用于设置服务器等待客户传输请求体的最大等待时间。</p></li></ul><p>注意<code>connectionTimeout</code>和<code>connectionUploadTimeout</code>，这两个参数分别设置了传输请求头与请求体的最大等待时间。<code>QBus</code>的线上配置是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector port=&quot;8080&quot;</span><br><span class="line">                executor=&quot;tomcatThreadPool&quot;</span><br><span class="line">                protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;</span><br><span class="line">                URIEncoding=&quot;UTF-8&quot;</span><br><span class="line">                enableLookups=&quot;false&quot;</span><br><span class="line">                connectionTimeout=&quot;30000&quot;</span><br><span class="line">                keepAliveTimeout=&quot;30000&quot;</span><br><span class="line">                disableUploadTimeout=&quot;false&quot;</span><br><span class="line">                connectionUploadTimeout=&quot;600000&quot;</span><br><span class="line">                acceptCount=&quot;500&quot;</span><br><span class="line">                useSendfile=&quot;false&quot;</span><br><span class="line">                compression=&quot;off&quot;</span><br><span class="line">                redirectPort=&quot;8443&quot;/&gt;</span><br></pre></td></tr></table></figure><h4 id="5-5_TCP参数">5.5 TCP参数</h4><ul><li><p><code>tcpNoDelay</code><br><br>用于开启或者关闭<code>Nagle</code>算法。<code>Nagle</code>算法，会将小的<code>TCP</code>包合并成一个大的包再进行发送，避免过多的小报文的TCP头的资源消耗。通常在交互性比较强的应用中会关闭<code>Nagle</code>算法，默认是开启的。</p></li><li><p><code>connectionLinger</code><br><br>与<code>TCP</code>的<code>SO_LINGER</code>的选项一致，用于控制<code>TCP</code>的<code>close</code>行为。<code>SO_LINGER</code>通常有三个取值：</p><ol><li>-1，会将<code>socket</code>发送缓存区中的数据发送完成后，才关闭<code>socket</code></li><li>0，通过发送RST分组(而不是用正常的FIN|ACK|FIN|ACK四个分组)来关闭该连接，并放弃发送缓存区中的数据。</li><li>大于0，关闭时，进程将进入睡眠状态，内核通过定时器在超时前尽量发送数据，如果发送完成，则正常关闭，否则超时后，直接通过<code>RST</code>进行关闭，丢弃发送缓存区中的数据。</li></ol></li><li><p><code>deferAccept</code><br><br>与<code>TCP</code>中的<code>TCP_DEFER_ACCEPT</code>选项一致。在解释<code>TCP_DEFER_ACCEPT</code>参数前，先解释一下<code>TCP</code>的三次握手:</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Client -&gt; Server：客户端给服务器发送SYN包</span><br><span class="line">2. Client &lt;- Server: 服务器在收到SYN包后，将返给客户SYN + ACK，Server端的连接为SYN_RECV状态</span><br><span class="line">3. Client -&gt; Server: 客户端收到SYN+ACK包后，向服务器发送ACK包，Client和Server端的连接均为ESTABLISHED</span><br></pre></td></tr></table></figure><p>  通常服务器在接受到最后的一个<code>ACK</code>包后，将进入<code>ESTABLISH</code>状态。此过程会出现一个问题，当服务器已经打开了连接，但是如果客户端一直不发数据的话，会占用服务器的资源。而<code>TCP_DEFER_ACCEPT</code>选项开启后，在接受到最后一个<code>ACK</code>后，并不会进入<code>ESTABLISH</code>状态，也并不会真正建立连接，而是保持在<code>SYN_RECV</code>状态，只是标记当前<code>socket</code>，当客户端的数据真正到来时，才建立连接。通常是需要开启<code>延迟ACK</code>，将<code>ACK</code>与数据一起发送，才能建立连接。</p></li><li><p><code>useSendfile</code><br><br>用于开启或者关闭<strong>零拷贝机制</strong>，该机制，通过减少数据在用户态和内核态的拷贝，从而提高性能。</p></li></ul><h4 id="5-6_Tomcat的注意点">5.6 Tomcat的注意点</h4><ul><li><code>Spring</code>项目，尽量不要将项目调整成<code>root</code>目录，否则有可能你会遇到某一个<code>bean</code>会被初始化两次的问题</li><li>一个<code>Tomcat</code>尽量只有一个项目</li></ul><h3 id="六、代码层面上的优化">六、代码层面上的优化</h3><p>代码方面，主要引入了内存级别的缓存层，将配置信息放入缓存，避免对数据库的读操作。多个进程间的缓存同步有两个机制进行保证:</p><ul><li>同步通过<code>QBus</code>本身进行同步</li><li>当从缓存中读取不到数据时，再读数据库，此时一定需要注意，避免出现<code>Dog Pipe Effect</code>现象</li></ul><p>加入缓存后，整个消息的发送时延多<code>40ms</code>降低到<code>10～15ms</code>之间。</p><h3 id="七、总结">七、总结</h3><p>以上就是<code>QBus</code>已经做过的优化，在孙哥(孙国峻)和我们沟通后，新版本的<code>QBus</code>中，我们将做如下的优化:</p><ol><li>减少对数据库的依赖，引入redis</li><li>模块分离，将<code>send</code>、<code>publish</code>、<code>ack</code>、<code>pull</code>与页面逻辑进行模块分离</li><li>针对<code>send</code>、<code>publish</code>、<code>ack</code>、<code>pull</code>接口，通过<code>netty</code>进行网络接连，这样可以自定义其<code>TCP</code>参数、连接池、线程池、网络模型等，而且除了能提高性能，同样也能给出详细的日志，比如metric信息、异常信息等，能更好地把控服务</li><li>优化日志，不直接写kafka，写文件，再同步到kafka，以便快速解决问题</li></ol><p>优化是一个长期过程，而要反复迭代，并且会很受到业务功能的影响，比如<code>QBus</code>的拉消息接口，其功能决定了这是一个慢操作，而发送消息、删除消息，就必须要保证尽可能快，所以相对而言，拉消息更消耗内存，而发送消息、删除消息接口更消耗CPU，所以优化时，也需要分开处理。欢迎大家补充指正。</p>]]></content>
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>配置中心选型</title>
      <link href="/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/Config/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B/"/>
      <url>/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/Config/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B/</url>
      <content type="html"><![CDATA[<h3 id="(一)_背景">(一) 背景</h3><h4 id="为什么需要配置中心">为什么需要配置中心</h4><p>传统的基于文件的配置方式，存在很多问题，诸如: 修改配置需要重新部署，权限控制、不同的环境需要重新编译等等。配置中心将所有的配置集中控制，提供方便的配置方式、热部署、修改配置后代码自动感知，能提供便利的同时，减少开发的复杂度。公司的项目越来越多，配置中心则变成越来越急迫。</p><h4 id="已有zookeeper、etcd还需要引入吗？">已有zookeeper、etcd还需要引入吗？</h4><p><code>zookeeper</code>、<code>etcd</code>并没有方便的UI管理工具，且缺乏权限、审核等机制，使用并不方便，最重要的是，<code>etcd</code>和<code>zookeeper</code>通常定义为服务注册中心，并非配置中心。</p><h4 id="有哪些开源配置中心">有哪些开源配置中心</h4><ul><li><p>spring-cloud/spring-cloud-config<br>  <a href="https://github.com/spring-cloud/spring-cloud-config" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-config</a><br>  spring出品，可以和spring cloud无缝配合</p></li><li><p>淘宝 diamond<br>  <a href="https://github.com/takeseem/diamond" target="_blank" rel="noopener">https://github.com/takeseem/diamond</a><br>  已经不维护</p></li><li><p>disconf<br>  <a href="https://github.com/knightliao/disconf" target="_blank" rel="noopener">https://github.com/knightliao/disconf</a><br>  java开发，蚂蚁金服技术专家发起，在百度、滴滴等大公司内广泛使用</p></li><li><p>ctrip apollo<br>  <a href="https://github.com/ctripcorp/apollo/" target="_blank" rel="noopener">https://github.com/ctripcorp/apollo/</a><br>  Apollo（阿波罗）是携程框架部门研发的开源配置管理中心，具备规范的权限、流程治理等特性。</p></li></ul><h3 id="我们需要的功能有哪些">我们需要的功能有哪些</h3><ol><li>可以在界面上配置</li><li>通过Http请求获取最新配置</li><li>支持多环境</li><li>配置变更，通过http请求接受到通知</li><li>提供API接口，用于修改参数</li><li>权限、审计功能完善</li><li>高可用、健壮</li><li>活跃度高</li></ol><h3 id="(二)_配置中心如何选择？">(二) 配置中心如何选择？</h3><p>基于公司的情况，我们首先会排除<code>spring-cloud-config</code>和<code>diamond</code>，<code>spring-cloud-config</code>是<code>spring cloud</code>和<code>spring boot</code>的一部分，这将限制其语言只能是<code>java</code>和<code>spring</code>框架，而我们公司项目所使用的语言很多，不仅仅有<code>Java</code>还有<code>Go</code>、<code>php</code>，所以会排除<code>spring-cloud-config</code>。而<code>diamond</code>现在已经不开源，在<code>github</code>的项目大多是很早之前<code>diamond</code>开源出来时而<code>fork</code>出来的分支，所以<code>diamond</code>也不考虑。接下来，从各个方面深入比较<code>disconf</code>和<code>apollo</code>项目。</p><table><thead><tr><th>功能点</th><th>优先级</th><th>disconf</th><th>apollo</th></tr></thead><tbody><tr><td>可以在界面上配置</td><td>高</td><td>支持</td><td>支持</td></tr><tr><td>通过Http请求获取最新配置</td><td>高</td><td>支持</td><td>支持</td></tr><tr><td>支持多环境</td><td>高</td><td>支持</td><td>支持</td></tr><tr><td>配置变更，通过http请求接受到通知</td><td>高</td><td>不支持</td><td>不支持</td></tr><tr><td>提供API接口，用于修改参数</td><td>中</td><td>支持</td><td>支持</td></tr><tr><td>权限、审计功能完善</td><td>中</td><td>不支持</td><td>支持</td></tr><tr><td>高可用、健壮</td><td>高</td><td>高可用</td><td>高可用</td></tr><tr><td>活跃度高</td><td>高</td><td>活跃度不高，在github上最新一次修改是2年前</td><td>活跃度很高，最近一次修改在2018年10月10号</td></tr><tr><td>依赖项</td><td>高</td><td>依赖于mysql、tomcat、nginx、zookeeper、redis</td><td>依赖于mysql、eureka</td></tr><tr><td>客户端的支持</td><td>高</td><td>只支持Java客户端</td><td>客户端支持Java、php、Go、.Net等，Java和.Net是官方支持的，其它是社区开发</td></tr></tbody></table><h4 id="Disconf的优点"><code>Disconf</code>的优点</h4><p>项目出现比较早，经过了很多大公司的实践，高可用和稳定性方面都是毋庸置疑的</p><h4 id="Disconf的缺点"><code>Disconf</code>的缺点</h4><ol><li>项目很久没有更新，即是缺点也是优点，说明该项目很稳定，但是同时，如果有新的功能，也只能是自己开发</li><li>功能比较基础，无权限、审计功能，界面也很简单</li><li>依赖项比较多，不仅仅依赖于<code>zookeeper</code>，还依赖于<code>redis</code>，而且<code>redis</code>必须为集群</li><li>部署麻烦，依赖于<code>tomcat</code>、<code>nginx</code></li></ol><h4 id="Apollo的优点"><code>Apollo</code>的优点</h4><ol><li>使用该项目的公司越来越多</li><li>功能强大: 权限、审计、灰度、版本控制，几乎你能想到，并且实际可用的功能都已经有了</li><li>文档完整</li><li>部署简单，部署的包都是<code>jar</code></li><li>仅仅只是依赖于<code>mysql</code>和<code>eureka</code>，并且<code>eureka</code>已经集成到<code>jar</code>中，并不需要自己维护</li></ol><h4 id="Apollo的缺点"><code>Apollo</code>的缺点</h4><p>虽然越来越多的公司接入<code>Apollo</code>，但是<code>Apollo</code>相对于<code>Disconf</code>而言，还是更年轻，并且版本并不稳定，更新频率比较高。</p><p>最终的还是选择<strong><code>Apollo</code></strong>项目。</p><h3 id="(三)_如何解决配置变更，通过Http请求通知相应服务？">(三) 如何解决配置变更，通过Http请求通知相应服务？</h3><p>可借助公司内部的<code>QBus</code>项目进行实现。</p>]]></content>
      
      <categories>
          
          <category> 配置中心 </category>
          
      </categories>
      
      
    </entry>
    
  
  
</search>
